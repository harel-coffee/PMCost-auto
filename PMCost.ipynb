{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gc\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import networkx as nx\n",
    "\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import r2_score as R2\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense,Input,LSTM,Embedding\n",
    "from keras.layers import Dropout,Activation\n",
    "from keras.layers import Bidirectional,GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import common_texts\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.__version__.split('.')[0] == 2:\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/eclipse-total.csv')\n",
    "codefeature = pd.read_csv('data/eclipse-codefeature.csv')\n",
    "cutted_file = 'data/cutted.csv'\n",
    "EMBEDDING_FILE = 'data/embedding.model'\n",
    "FEATURE_RESULT = 'data/eclipse-all-features.csv'\n",
    "kfold = TimeSeriesSplit(n_splits=10)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDF ( Generated via Java )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changetype = codefeature.groupby('Index')['ChangeType'].value_counts().unstack().fillna(0).reset_index()\n",
    "changeratio = (codefeature.groupby('Index')['Delta'].sum() / codefeature.groupby('Index')['TotalLines'].sum()).to_frame()\n",
    "changeratio.columns = ['ChangeRatio']\n",
    "cdf = pd.merge(data.Index, changetype, on='Index', how='left')\n",
    "cdf = pd.merge(cdf, changeratio, on='Index', how='left').fillna(0)\n",
    "cdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF ( w2v feature )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = data[['Index', 'changedesc']]\n",
    "cm.changedesc = cm.changedesc.str.replace('\\[|\\]|\\'|\\.|\\t|\\r|\\n|:|/',' ')\n",
    "cm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm.to_csv(cutted_file, index=False)\n",
    "tmp = gensim.models.word2vec.LineSentence(cutted_file, max_sentence_length=20)\n",
    "model= Word2Vec(workers=20,sentences=tmp,window=3, min_count=5,iter = 5,size=50)\n",
    "print(len(model.wv.vocab))\n",
    "model.save(EMBEDDING_FILE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 4000\n",
    "maxlen = 25\n",
    "batch_size = 50\n",
    "tokenizer = Tokenizer()\n",
    "# traing text\n",
    "tokenizer.fit_on_texts(list(model.wv.vocab))\n",
    "list_sentences_train = cm['changedesc'].astype(str)\n",
    "tokenizer = Tokenizer(num_words = max_features)\n",
    "# traing text\n",
    "tokenizer.fit_on_texts(list_sentences_train.tolist())\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train) \n",
    " # 列长度\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadEmbeddingMatrix(typeToLoad,EMBEDDING_FILE,tokenizer):\n",
    "    if typeToLoad == 'word2vec':\n",
    "        word2vecDict = gensim.models.KeyedVectors.load(EMBEDDING_FILE)\n",
    "        embedding_index = dict()\n",
    "        # 词与对应词向量\n",
    "        for word in word2vecDict.wv.vocab:\n",
    "            embedding_index[word] = word2vecDict.wv.word_vec(word) # 对应的(300,)的词向量\n",
    "        print('Load %s word vectors.' % len(embedding_index))\n",
    "    gc.collect()\n",
    "    all_embs = np.stack(list(embedding_index.values())) # （3000000,300）\n",
    "    emb_mean,emb_std = all_embs.mean(),all_embs.std()\n",
    "    nb_words = len(tokenizer.word_index) # 训练词的个数\n",
    "    # 权重矩阵随机初始化\n",
    "    embedding_matrix = np.random.normal(emb_mean,emb_std,(nb_words+1,50))\n",
    "    gc.collect()\n",
    "    embeddedCount = 0\n",
    "    for word,i in tokenizer.word_index.items(): # 词\n",
    "    #         i -= 1\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            embeddedCount += 1\n",
    "    print('total_embedded:',embeddedCount,'common words')\n",
    "    del embedding_index\n",
    "    gc.collect()\n",
    "    return embedding_matrix\n",
    "def getvec(X_t,embedding_matrix):\n",
    "    tf.reset_default_graph()\n",
    "    graph = tf.Graph() \n",
    "\n",
    "    # with graph.as_default():  \n",
    "    train_inputs1 = tf.placeholder(tf.int32, shape=(None,maxlen),name = 'x')          \n",
    "    embeddings = tf.Variable(embedding_matrix,name = 'embed')\n",
    "    embed = tf.nn.embedding_lookup(embeddings, train_inputs1);  \n",
    "    print('shape of embed1 : \\t', str(embed.get_shape()))  \n",
    "\n",
    "    #layer 1         \n",
    "    vec = tf.reduce_mean(embed, axis = 1)  \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as session:  \n",
    "        init.run() \n",
    "        print('inited')  \n",
    "        average_loss = 0  \n",
    "        vecs = []  \n",
    "        nstep=int(len(X_t)/batch_size)+1\n",
    "\n",
    "        for step in trange(nstep):  \n",
    "            x1=generate_batch(X_t,step) \n",
    "            feed_dict = {train_inputs1 : x1}\n",
    "            vecblock = session.run([vec], feed_dict=feed_dict) \n",
    "            vecs += vecblock\n",
    "        vecs = np.vstack(vecs)\n",
    "    return vecs\n",
    "def generate_batch(X_t,step): \n",
    "    if (step+1)*batch_size>len(X_t):\n",
    "        batchdata = X_t[batch_size*step:]\n",
    "    else:\n",
    "        batchdata = X_t[batch_size*step:batch_size*(step+1)]\n",
    "    return batchdata   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = loadEmbeddingMatrix('word2vec', EMBEDDING_FILE, tokenizer)\n",
    "vecs = getvec(X_t, embedding_matrix)\n",
    "yyuid = data.Index\n",
    "w2v = pd.DataFrame(yyuid,columns = ['Index'])\n",
    "w2v['vec'] = np.round(vecs,decimals=5).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = pd.concat([w2v['Index'], w2v['vec'].astype('str').str.strip('[]').str.split(',', expand=True).astype('float')],axis=1)\n",
    "w2v.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMF ( Meta )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Branch.fillna('', inplace=True)\n",
    "data.Project.fillna('', inplace=True)\n",
    "data['Owner'] = data['Owner'].map(lambda x: x.lower())\n",
    "data['Author'] = data['Author'].map(lambda x: x.lower())\n",
    "data['hour'] = data['Time'].apply(lambda x: int(x.split(':')[0]))\n",
    "\n",
    "data['OwnerLabel'] = LabelEncoder().fit_transform(data['Owner'])\n",
    "data['AuthorLabel'] = LabelEncoder().fit_transform(data['Author'])\n",
    "data['ProjectLabel'] = LabelEncoder().fit_transform(data['Project'])\n",
    "data['BranchLabel'] = LabelEncoder().fit_transform(data['Branch'])\n",
    "\n",
    "data['MessageLength'] = data['changedesc'].fillna(\"\").apply(lambda x: len(re.split('\\s', x)))\n",
    "data['SubmitDay'] = data['starttime'].apply(lambda x: int(x.split('-')[2].split(' ')[0]))\n",
    "\n",
    "meta = ['OwnerLabel', 'AuthorLabel', 'ProjectLabel', 'hour', 'MessageLength',\n",
    "        'SubmitDay', 'relatedNum', 'JavaFileNum', 'BranchLabel', 'ReviewerNum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Reviewerword'] = data['Reviewer'].apply(lambda x: x.strip('[]').split(','))\n",
    "data['Reviewerword'] = data['Reviewerword'].apply(lambda x: [i.lower().strip(\" |  |'\").strip(' ') for i in x])\n",
    "owners = list(data['Owner'].unique())\n",
    "reviewers=[]\n",
    "for i in data['Reviewerword']:\n",
    "    reviewers += i\n",
    "reviewers = list(set(reviewers))\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(owners + reviewers)\n",
    "tmp = data['Reviewer'].copy()\n",
    "tmp.index = data['Owner']\n",
    "tmp = tmp.astype(str).str.strip('[]').str.lower().str.split(',', expand=True).stack().reset_index().drop('level_1',axis = 1)\n",
    "tmp.columns=['OwnerLabel','ReviewerLabel']\n",
    "tmp['ReviewerLabel'] = tmp['ReviewerLabel'].map(lambda x: x.strip(\" |  |'\").strip(' '))\n",
    "tmp['OwnerLabel'] = encoder.transform(tmp['OwnerLabel'])\n",
    "tmp['ReviewerLabel'] = encoder.transform(tmp['ReviewerLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(zip(tmp['OwnerLabel'], tmp['ReviewerLabel']))\n",
    "G = nx.DiGraph()\n",
    "G = nx.DiGraph(name='my graph')  \n",
    "G = nx.DiGraph(edges)\n",
    "# nx.draw(G)\n",
    "\n",
    "dc = nx.degree_centrality(G)\n",
    "cc = nx.closeness_centrality(G)\n",
    "bc= nx.betweenness_centrality(G)\n",
    "absdegree = dict(nx.degree(G))\n",
    "indc = nx.in_degree_centrality(G)\n",
    "outdc = nx.out_degree_centrality(G)\n",
    "CNfea1 = data.Index.to_frame()\n",
    "CNfea1['degree_centrality'] = data['OwnerLabel'].map(dc)\n",
    "CNfea1['closeness_centrality'] = data['OwnerLabel'].map(cc)\n",
    "CNfea1['betweenness_centrality'] = data['OwnerLabel'].map(bc)\n",
    "CNfea1['degree'] = data['OwnerLabel'].map(absdegree)\n",
    "CNfea1['in_degree_centrality'] = data['OwnerLabel'].map(indc)\n",
    "CNfea1['out_degree_centrality'] = data['OwnerLabel'].map(outdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data['Reviewer'].copy()\n",
    "tmp.index = data['Index']\n",
    "tmp = tmp.astype(str).str.strip('[]').str.lower().str.split(',', expand=True).stack().reset_index().drop('level_1',axis = 1)\n",
    "tmp.columns=['Index','ReviewerLabel']\n",
    "tmp['ReviewerLabel'] = tmp['ReviewerLabel'].map(lambda x: x.strip(\" |  |'\").strip(' '))\n",
    "\n",
    "tmp['ReviewerLabel'] = encoder.transform(tmp['ReviewerLabel'])\n",
    "tmp['degree_centrality'] = tmp.ReviewerLabel.map(dc)\n",
    "tmp['closeness_centrality'] = tmp.ReviewerLabel.map(cc)\n",
    "tmp['betweenness_centrality'] = tmp.ReviewerLabel.map(bc)\n",
    "tmp['degree'] = tmp.ReviewerLabel.map(absdegree)\n",
    "tmp['in_degree_centrality'] = tmp.ReviewerLabel.map(indc)\n",
    "tmp['out_degree_centrality'] = tmp.ReviewerLabel.map(outdc)\n",
    "\n",
    "CNfea2 = tmp[['Index','degree_centrality','closeness_centrality','degree','in_degree_centrality',\n",
    "              'out_degree_centrality']].groupby('Index').agg(['mean','sum']).add_prefix('review_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CN = CNfea1.merge(CNfea2,on = 'Index',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORE={}\n",
    "ORE['ownerpassratio'] = data.groupby('OwnerLabel').PatchTime.agg(np.mean).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data['Reviewer'].copy()\n",
    "tmp.index = data['Index']\n",
    "tmp = tmp.astype(str).str.strip('[]').str.lower().str.split(',', expand=True).stack().reset_index().drop('level_1',axis = 1)\n",
    "tmp.columns = ['Index', 'Reviewer']\n",
    "tmp['ReviewerLabel'] = tmp['Reviewer'].map(lambda x: x.strip(\" |  |'\").strip(' '))\n",
    "tmp['ReviewerLabel'] = encoder.transform(tmp['ReviewerLabel'])\n",
    "tmp = tmp.merge(data,on='Index',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORE['reviewerpassratio'] = tmp.groupby('ReviewerLabel')['PatchTime'].agg(np.mean).to_dict()\n",
    "OREfea1 = data['Index'].to_frame()\n",
    "OREfea1['ownerpassratio'] = data['OwnerLabel'].map(ORE['ownerpassratio'])\n",
    "\n",
    "tmp['reviewerpassratio'] = tmp['ReviewerLabel'].map(ORE['reviewerpassratio'])\n",
    "OREfea2 = tmp.groupby('Index').agg({'reviewerpassratio':[np.mean,sum,max,min]}).reset_index()\n",
    "OREfea = OREfea1.merge(OREfea2,on='Index',how='left')\n",
    "\n",
    "PEF = CN.merge(OREfea, on='Index', how='left')\n",
    "PEF.drop_duplicates(keep='first', inplace=True)\n",
    "PEF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultSet:\n",
    "    def __init__(self, _name):\n",
    "        self.name = _name\n",
    "        self.acc = []\n",
    "        self.prec = []\n",
    "        self.rec = []\n",
    "        self.f1 = []\n",
    "\n",
    "def deal_score(result, y_true, pred, mask=False):\n",
    "    if not mask:\n",
    "        result.acc.append(accuracy_score(y_true, pred))\n",
    "        result.prec.append(precision_score(y_true, pred))\n",
    "        result.rec.append(recall_score(y_true, pred))\n",
    "        result.f1.append(f1_score(y_true, pred))\n",
    "    else:\n",
    "        result.acc.append(np.nan_to_num(accuracy_score(y_true.iloc[mask], pred[mask])))\n",
    "        result.prec.append(np.nan_to_num(precision_score(y_true.iloc[mask], pred[mask])))\n",
    "        result.rec.append(np.nan_to_num(recall_score(y_true.iloc[mask], pred[mask])))\n",
    "        result.f1.append(np.nan_to_num(f1_score(y_true.iloc[mask], pred[mask])))\n",
    "\n",
    "def print_score(result):\n",
    "    print(\"|{}|{:.2%}|{:.2%}|{:.2%}|{:.2%}|\".format(\n",
    "            result.name, np.mean(result.acc),\n",
    "            np.mean(result.prec), np.mean(result.rec),\n",
    "            np.mean(result.f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(X, Y, name, clf, kfold):\n",
    "    result = ResultSet(name)\n",
    "    for trainindex,testindex in kfold.split(X):\n",
    "        x_train = X.iloc[trainindex,:]\n",
    "        x_test = X.iloc[testindex,:]\n",
    "        y_train = Y.iloc[trainindex]\n",
    "        y_test = Y.iloc[testindex]\n",
    "        if y_train.sum() * 3 < y_train.shape[0]:\n",
    "            pos_cnt = (y_train.shape[0] - y_train.sum()) // 2\n",
    "            neg_cnt = y_train.shape[0] - y_train.sum()\n",
    "        else:\n",
    "            pos_cnt = y_train.sum()\n",
    "            neg_cnt = pos_cnt * 2\n",
    "        smo = SMOTE(sampling_strategy={0: neg_cnt, 1 : pos_cnt}, random_state=42)\n",
    "        x_train, y_train = smo.fit_sample(np.array(x_train), np.array(y_train))\n",
    "        clf.fit(x_train, y_train)\n",
    "        prediction = clf.predict(x_test)\n",
    "        deal_score(result, y_test, prediction)\n",
    "    print_score(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_guess(X, Y, kfold):\n",
    "    result = ResultSet(\"RandomGuess\")\n",
    "    for trainindex,testindex in kfold.split(X):\n",
    "        x_train = X.iloc[trainindex,:]\n",
    "        x_test = X.iloc[testindex,:]\n",
    "        y_train = Y.iloc[trainindex]\n",
    "        y_test = Y.iloc[testindex]\n",
    "        prob = y_train.sum() / y_train.shape[0]\n",
    "        prediction = np.random.choice([0, 1], size=y_test.shape[0], p=[1 - prob, prob])\n",
    "        deal_score(result, y_test, prediction)\n",
    "    print_score(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_gbm(X, Y, kfold):\n",
    "    result = ResultSet(\"LightGBM\")\n",
    "    for trainindex,testindex in kfold.split(X):\n",
    "        x_train = X.iloc[trainindex,:]\n",
    "        x_test = X.iloc[testindex,:]\n",
    "        y_train = Y.iloc[trainindex]\n",
    "        y_test = Y.iloc[testindex]\n",
    "        if y_train.sum() * 3 < y_train.shape[0]:\n",
    "            pos_cnt = (y_train.shape[0] - y_train.sum()) // 2\n",
    "            neg_cnt = y_train.shape[0] - y_train.sum()\n",
    "        else:\n",
    "            pos_cnt = y_train.sum()\n",
    "            neg_cnt = pos_cnt * 2\n",
    "        smo = SMOTE(sampling_strategy={0: neg_cnt, 1 : pos_cnt}, random_state=42)\n",
    "        x_train, y_train = smo.fit_sample(np.array(x_train), np.array(y_train))\n",
    "        x_tr = lgb.Dataset(x_train, label=y_train)\n",
    "        x_te = lgb.Dataset(x_test, label=y_test)\n",
    "        params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt',  # 设置提升类型\n",
    "            'objective': 'binary', # 目标函数\n",
    "            'metric': {'l2', 'auc'},  # 评估函数\n",
    "            'num_leaves': 31,   # 叶子节点数\n",
    "            'learning_rate': 0.05,  # 学习速率\n",
    "            'feature_fraction': 0.9, # 建树的特征选择比例\n",
    "            'bagging_fraction': 0.9, # 建树的样本采样比例\n",
    "            'bagging_freq': 5,  # k 意味着每 k 次迭代执行bagging\n",
    "            'verbose': -1, # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "        }\n",
    "        bst = lgb.train(params, x_tr, 3000, valid_sets=[x_te], early_stopping_rounds=10, verbose_eval=False) \n",
    "        prediction = bst.predict(x_test)\n",
    "        deal_score(result, y_test, prediction > 0.5)\n",
    "    print_score(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(X, Y, name, model, kfold):\n",
    "    mse_scores=[]\n",
    "    mae_scores=[]\n",
    "    r2_scores=[]\n",
    "    for trainindex,testindex in kfold.split(X):\n",
    "        x_train = X.iloc[trainindex,:]\n",
    "        x_test = X.iloc[testindex,:]\n",
    "        y_train = Y.iloc[trainindex]\n",
    "        y_test = Y.iloc[testindex]\n",
    "        model.fit(x_train, y_train)\n",
    "        prediction = model.predict(x_test)\n",
    "        mse_scores.append(MSE(y_test, prediction))\n",
    "        mae_scores.append(MAE(y_test, prediction))\n",
    "        r2_scores.append(R2(y_test, prediction))\n",
    "    print(f\"|{name}|\",\n",
    "          \"{:.4}|\".format(np.mean(mse_scores)),\n",
    "          \"{:.4}|\".format(np.mean(mae_scores)),\n",
    "          \"{:.4}|\".format(np.mean(r2_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_regression(X, Y, kfold):\n",
    "    mse_scores=[]\n",
    "    mae_scores=[]\n",
    "    r2_scores=[]\n",
    "    for trainindex,testindex in kfold.split(X):\n",
    "        x_train = X.iloc[trainindex,:]\n",
    "        x_test = X.iloc[testindex,:]\n",
    "        y_train = Y.iloc[trainindex]\n",
    "        y_test = Y.iloc[testindex]\n",
    "        x_tr = lgb.Dataset(x_train, label=y_train)\n",
    "        x_te = lgb.Dataset(x_test, label=y_test)\n",
    "        params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt',  # 设置提升类型\n",
    "            'objective': 'binary', # 目标函数\n",
    "            'metric': {'l2', 'auc'},  # 评估函数\n",
    "            'num_leaves': 31,   # 叶子节点数\n",
    "            'learning_rate': 0.05,  # 学习速率\n",
    "            'feature_fraction': 0.9, # 建树的特征选择比例\n",
    "            'bagging_fraction': 0.9, # 建树的样本采样比例\n",
    "            'bagging_freq': 5,  # k 意味着每 k 次迭代执行bagging\n",
    "            'verbose': -1, # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "        }\n",
    "        bst = lgb.train(params, x_tr, 3000, valid_sets=[x_te], early_stopping_rounds=10, verbose_eval=False) \n",
    "        prediction = bst.predict(x_test)\n",
    "        mse_scores.append(MSE(y_test, prediction))\n",
    "        mae_scores.append(MAE(y_test, prediction))\n",
    "        r2_scores.append(R2(y_test, prediction))\n",
    "    print(\"\\n|LGB|\",\n",
    "          \"{:.4}|\".format(np.mean(mse_scores)),\n",
    "          \"{:.4}|\".format(np.mean(mae_scores)),\n",
    "          \"{:.4}|\".format(np.mean(r2_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.sort_values(by='starttime', inplace=True)\n",
    "total = pd.merge(data[meta + ['Index', 'PatchTime']], cdf, on='Index', how='left')\n",
    "total = pd.merge(total, w2v, on='Index', how='left')\n",
    "total = pd.merge(total, PEF, on='Index', how='left')\n",
    "X = total.drop(['Index', 'PatchTime'], axis=1).fillna(0)\n",
    "Y = total['PatchTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"||MSE|MAE|R2|\\n|-|-|-|-|\")\n",
    "model = SVR()\n",
    "regression(X, Y, \"SVR\", model, kfold)\n",
    "model = MLPRegressor()\n",
    "regression(X, Y, \"MLP\", model, kfold)\n",
    "model = DecisionTreeRegressor()\n",
    "regression(X, Y, \"DT\", model, kfold)\n",
    "model = RandomForestRegressor()\n",
    "regression(X, Y, \"RF\", model, kfold)\n",
    "lgb_regression(X, Y, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. one-time merged: 1\n",
    "2. short-time merged: 2 - 6\n",
    "3. long-time merged: > 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label1(x):\n",
    "    return int(x == 1)\n",
    "def label2(x):\n",
    "    return int(x >= 2 and x <= 6)\n",
    "def label3(x):\n",
    "    return int(x > 6)\n",
    "\n",
    "labels = [('one-time', label1), ('short-time', label2), ('long-time', label3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by='starttime', inplace=True)\n",
    "data.reset_index(inplace=True)\n",
    "data.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.merge(data[meta + ['Index', 'PatchTime']], cdf, on='Index', how='left')\n",
    "total = pd.merge(total, w2v, on='Index', how='left')\n",
    "total = pd.merge(total, PEF, on='Index', how='left')\n",
    "total.fillna(0).to_csv(FEATURE_RESULT, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"||acc|prec|recall|f1|\\n|-|-|-|-|-|\")\n",
    "for lb_type, tolabel in labels:\n",
    "    total['label'] = total['PatchTime'].apply(tolabel)\n",
    "    X = total.drop(['Index', 'PatchTime', 'label'], axis=1).fillna(0)\n",
    "    Y = total['label']\n",
    "\n",
    "    random_guess(X, Y, kfold)\n",
    "    clf = LogisticRegression(n_jobs=16)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-LR\", clf, kfold)\n",
    "    clf = SVC(gamma=0.1)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-SVM\", clf, kfold)\n",
    "    clf = MLPClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-MLP\", clf, kfold)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-DT\", clf, kfold)\n",
    "    clf = RandomForestClassifier(n_jobs=16)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-RF\", clf, kfold)\n",
    "    light_gbm(X, Y, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The performance of PMCost for the patches submitted by new developers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['NewDeveloper'] = 0\n",
    "df = data.groupby('Owner').count().sort_values(by='Author')\n",
    "cnt = 0\n",
    "test_size = data.shape[0] // 10 # 10-folds\n",
    "for owner, row in df.iterrows():\n",
    "    cnt += row[0]\n",
    "    if cnt > test_size:\n",
    "        break\n",
    "    data.loc[data['Owner'] == owner, 'NewDeveloper'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  train by total and test respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"||acc|prec|recall|f1|\\n|-|-|-|-|-|\")\n",
    "for lb_type, tolabel in labels:\n",
    "    total['label'] = total['PatchTime'].apply(tolabel)\n",
    "    X = total.drop(['Index', 'PatchTime', 'label'], axis=1).fillna(0)\n",
    "    Y = total['label']\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1)\n",
    "    merged_new = ResultSet(f\"{lb_type}-merged_new')\n",
    "    merged_exp = ResultSet(f\"{lb_type}-merged_exp')\n",
    "    abandoned_new = ResultSet(f\"{lb_type}-abandoned_new')\n",
    "    abandoned_exp = ResultSet(f\"{lb_type}-abandoned_exp')\n",
    "\n",
    "    for trainindex,testindex in kfold.split(X):\n",
    "        x_train = X.iloc[trainindex,:]\n",
    "        x_test = X.iloc[testindex,:]\n",
    "        y_train = Y.iloc[trainindex]\n",
    "        y_test = Y.iloc[testindex]\n",
    "        if y_train.sum() * 3 < y_train.shape[0]:\n",
    "            pos_cnt = (y_train.shape[0] - y_train.sum()) // 2\n",
    "            neg_cnt = y_train.shape[0] - y_train.sum()\n",
    "        else:\n",
    "            pos_cnt = y_train.sum()\n",
    "            neg_cnt = pos_cnt * 2\n",
    "        smo = SMOTE(sampling_strategy={0: neg_cnt, 1 : pos_cnt}, random_state=42)\n",
    "        x_train, y_train = smo.fit_sample(np.array(x_train), np.array(y_train))\n",
    "        clf.fit(x_train, y_train)\n",
    "        prediction = clf.predict(x_test)\n",
    "\n",
    "        df = data.iloc[testindex].reset_index().drop('index', axis=1)\n",
    "        merged_new_mask = df[(df['status'] == 'MERGED') & (df['NewDeveloper'] == 1)].index\n",
    "        merged_exp_mask = df[(df['status'] == 'MERGED') & (df['NewDeveloper'] == 0)].index\n",
    "        abandoned_new_mask = df[(df['status'] == 'ABANDONED') & (df['NewDeveloper'] == 1)].index\n",
    "        abandoned_exp_mask = df[(df['status'] == 'ABANDONED') & (df['NewDeveloper'] == 0)].index\n",
    "        deal_score(merged_new, y_test, prediction, merged_new_mask)\n",
    "        deal_score(merged_exp, y_test, prediction, merged_exp_mask)\n",
    "        deal_score(abandoned_new, y_test, prediction, abandoned_new_mask)\n",
    "        deal_score(abandoned_exp, y_test, prediction, abandoned_exp_mask)\n",
    "    print(\"||acc|prec|recall|f1|\\n|-|-|-|-|-|\")\n",
    "    print_score(merged_new)\n",
    "    print_score(merged_exp)\n",
    "    print_score(abandoned_new)\n",
    "    print_score(abandoned_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### only new developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"||acc|prec|recall|f1|\\n|-|-|-|-|-|\")\n",
    "for lb_type, tolabel in labels:\n",
    "    total['label'] = total['PatchTime'].apply(tolabel)\n",
    "    X = total.drop(['Index', 'PatchTime', 'label'], axis=1).fillna(0)[data['NewDeveloper'] ==  1]\n",
    "    Y = total['label'][data['NewDeveloper'] ==  1]\n",
    "    clf = RandomForestClassifier(n_jobs=-1)\n",
    "    model_evaluate(X, Y, lb_type, clf, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### except PEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"||acc|prec|recall|f1|\\n|-|-|-|-|-|\")\n",
    "for lb_type, tolabel in labels:\n",
    "    total['label'] = total['PatchTime'].apply(tolabel)\n",
    "    X = total.drop(list(PEF.columns) + ['label'], axis=1).fillna(0)\n",
    "    Y = total['label']\n",
    "    clf = RandomForestClassifier(n_jobs=-1)\n",
    "    new = ResultSet(f\"{lb_type}-new')\n",
    "    exp = ResultSet(f\"{lb_type}-exp')\n",
    "\n",
    "    for trainindex,testindex in kfold.split(X):\n",
    "        x_train = X.iloc[trainindex,:]\n",
    "        x_test = X.iloc[testindex,:]\n",
    "        y_train = Y.iloc[trainindex]\n",
    "        y_test = Y.iloc[testindex]\n",
    "        if y_train.sum() * 3 < y_train.shape[0]:\n",
    "            pos_cnt = (y_train.shape[0] - y_train.sum()) // 2\n",
    "            neg_cnt = y_train.shape[0] - y_train.sum()\n",
    "        else:\n",
    "            pos_cnt = y_train.sum()\n",
    "            neg_cnt = pos_cnt * 2\n",
    "        smo = SMOTE(sampling_strategy={0: neg_cnt, 1 : pos_cnt}, random_state=42)\n",
    "        x_train, y_train = smo.fit_sample(np.array(x_train), np.array(y_train))\n",
    "        clf.fit(x_train, y_train)\n",
    "        prediction = clf.predict(x_test)\n",
    "\n",
    "        df = data.iloc[testindex].reset_index().drop('index', axis=1)\n",
    "        new_mask = df[df['NewDeveloper'] == 1].index\n",
    "        exp_mask = df[df['NewDeveloper'] == 0].index\n",
    "        deal_score(new, y_test, prediction, new_mask)\n",
    "        deal_score(exp, y_test, prediction, exp_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"||acc|prec|recall|f1|\\n|-|-|-|-|-|\")\n",
    "for lb_type, tolabel in labels:\n",
    "    X = pd.merge(data, cdf, on='Index', how='left')\n",
    "    Y = X['PatchTime'].apply(tolabel)\n",
    "    X = X.drop(data.columns, axis=1)\n",
    "    random_guess(X, Y, kfold)\n",
    "    clf = LogisticRegression(n_jobs=16)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-LR\", clf, kfold)\n",
    "    clf = SVC(gamma=0.1)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-SVM\", clf, kfold)\n",
    "    clf = MLPClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-MLP\", clf, kfold)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-DT\", clf, kfold)\n",
    "    clf = RandomForestClassifier(n_jobs=16)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-RF\", clf, kfold)\n",
    "    light_gbm(X, Y, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"||acc|prec|recall|f1|\\n|-|-|-|-|-|\")\n",
    "for lb_type, tolabel in labels:\n",
    "    X = pd.merge(data, w2v, on='Index', how='left')\n",
    "    Y = X['PatchTime'].apply(tolabel)\n",
    "    X = X.drop(data.columns, axis=1)\n",
    "    random_guess(X, Y, kfold)\n",
    "    clf = LogisticRegression(n_jobs=16)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-LR\", clf, kfold)\n",
    "    clf = SVC(gamma=0.1)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-SVM\", clf, kfold)\n",
    "    clf = MLPClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-MLP\", clf, kfold)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-DT\", clf, kfold)\n",
    "    clf = RandomForestClassifier(n_jobs=16)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-RF\", clf, kfold)\n",
    "    light_gbm(X, Y, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"||acc|prec|recall|f1|\\n|-|-|-|-|-|\")\n",
    "for lb_type, tolabel in labels:\n",
    "    data['label'] = data['PatchTime'].apply(tolabel)\n",
    "    X = data[meta]\n",
    "    Y = data['label']\n",
    "    random_guess(X, Y, kfold)\n",
    "    clf = LogisticRegression()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-LR\", clf, kfold)\n",
    "    clf = SVC(gamma=0.1)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-SVM\", clf, kfold)\n",
    "    clf = MLPClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-MLP\", clf, kfold)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-DT\", clf, kfold)\n",
    "    clf = RandomForestClassifier(n_jobs=-1)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-RF\", clf, kfold)\n",
    "    light_gbm(X, Y, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"||acc|prec|recall|f1|\\n|-|-|-|-|-|\")\n",
    "for lb_type, tolabel in labels:\n",
    "    X = pd.merge(data, PEF, on='Index', how='left')\n",
    "    Y = X['PatchTime'].apply(tolabel)\n",
    "    X = X.drop(data.columns, axis=1)\n",
    "    random_guess(X, Y, kfold)\n",
    "    clf = LogisticRegression(n_jobs=16)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-LR\", clf, kfold)\n",
    "    clf = SVC(gamma=0.1)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-SVM\", clf, kfold)\n",
    "    clf = MLPClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-MLP\", clf, kfold)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-DT\", clf, kfold)\n",
    "    clf = RandomForestClassifier(n_jobs=16)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-RF\", clf, kfold)\n",
    "    light_gbm(X, Y, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDF + TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"||acc|prec|recall|f1|\\n|-|-|-|-|-|\")\n",
    "for lb_type, tolabel in labels:\n",
    "    X = pd.merge(data, cdf, on='Index', how='left')\n",
    "    X = pd.merge(X, w2v, on='Index', how='left')\n",
    "    Y = X['PatchTime'].apply(tolabel)\n",
    "    X = X.drop(data.columns, axis=1)\n",
    "    random_guess(X, Y, kfold)\n",
    "    clf = LogisticRegression(n_jobs=16)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-LR\", clf, kfold)\n",
    "    clf = SVC(gamma=0.1)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-SVM\", clf, kfold)\n",
    "    clf = MLPClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-MLP\", clf, kfold)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-DT\", clf, kfold)\n",
    "    clf = RandomForestClassifier(n_jobs=16)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-RF\", clf, kfold)\n",
    "    light_gbm(X, Y, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDF + TF + PMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"||acc|prec|recall|f1|\\n|-|-|-|-|-|\")\n",
    "for lb_type, tolabel in labels:\n",
    "    X = pd.merge(data, cdf, on='Index', how='left')\n",
    "    X = pd.merge(X, w2v, on='Index', how='left')\n",
    "    Y = X['PatchTime'].apply(tolabel)\n",
    "    X = X.drop([x for x in data.columns if x not in meta], axis=1)\n",
    "    random_guess(X, Y, kfold)\n",
    "    clf = LogisticRegression()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-LR\", clf, kfold)\n",
    "    clf = SVC(gamma=0.1)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-SVM\", clf, kfold)\n",
    "    clf = MLPClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-MLP\", clf, kfold)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-DT\", clf, kfold)\n",
    "    clf = RandomForestClassifier(n_jobs=-1)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-RF\", clf, kfold)\n",
    "    light_gbm(X, Y, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = ['OwnerLabel','AuthorLabel','ProjectLabel','BranchLabel']\n",
    "print(\"||acc|prec|recall|f1|\\n|-|-|-|-|-|\")\n",
    "for lb_type, tolabel in labels:    \n",
    "    X = data[ID]\n",
    "    Y = data['PatchTime'].apply(tolabel)\n",
    "    random_guess(X, Y, kfold)\n",
    "    clf = LogisticRegression()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-LR\", clf, kfold)\n",
    "    clf = SVC(gamma=0.1)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-SVM\", clf, kfold)\n",
    "    clf = MLPClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-MLP\", clf, kfold)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-DT\", clf, kfold)\n",
    "    clf = RandomForestClassifier(n_jobs=-1)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-RF\", clf, kfold)\n",
    "    light_gbm(X, Y, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Owner Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"||acc|prec|recall|f1|\\n|-|-|-|-|-|\")\n",
    "for lb_type, tolabel in labels:\n",
    "    X = OREfea.merge(data[['Index', 'PatchTime']], on='Index')\n",
    "    Y = X['PatchTime'].apply(tolabel)\n",
    "    X = X.drop(['Index', 'PatchTime'], axis=1)\n",
    "    random_guess(X, Y, kfold)\n",
    "    clf = LogisticRegression(n_jobs=16)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-LR\", clf, kfold)\n",
    "    clf = SVC(gamma=0.1)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-SVM\", clf, kfold)\n",
    "    clf = MLPClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-MLP\", clf, kfold)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    model_evaluate(X, Y, f\"{lb_type}-DT\", clf, kfold)\n",
    "    clf = RandomForestClassifier(n_jobs=16)\n",
    "    model_evaluate(X, Y, f\"{lb_type}-RF\", clf, kfold)\n",
    "    light_gbm(X, Y, kfold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
